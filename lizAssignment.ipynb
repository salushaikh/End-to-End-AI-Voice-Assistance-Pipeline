{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Requirements Installation***\n",
        "\n"
      ],
      "metadata": {
        "id": "cjgHzhwOPnQ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "osh-g2ZJ10SS",
        "outputId": "0ec8fe65-3567-40d7-c2cb-54d9cf463d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.10/dist-packages (2.0.10)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: edge-tts in /usr/local/lib/python3.10/dist-packages (6.1.12)\n",
            "Collecting asyncio\n",
            "  Downloading asyncio-3.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: av<13,>=11.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (12.3.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (4.3.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.23.5)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (1.19.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: aiohttp>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from edge-tts) (3.10.5)\n",
            "Requirement already satisfied: certifi>=2023.11.17 in /usr/local/lib/python3.10/dist-packages (from edge-tts) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.0->edge-tts) (4.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (71.0.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.12.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: asyncio\n",
            "Successfully installed asyncio-3.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "asyncio"
                ]
              },
              "id": "0adbf2dc27204512a7ff2f48d8bbccd2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install faster-whisper ffmpeg-python webrtcvad edge-tts asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ollama Installation & Setup***"
      ],
      "metadata": {
        "id": "dN-R1pKTP1Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXiLMUGTa3lU",
        "outputId": "196d3ef7-d3c4-496f-c2c3-eb766f54cde2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 CLI\n",
            "############################################################################################# 100.0%\n",
            ">>> Making ollama accessible in the PATH in /usr/local/bin\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!ollama pull llama3.1:8b\n",
        "clear_output()\n",
        "\n",
        "!pip install -U lightrag[ollama]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iauz4omTbA-1",
        "outputId": "0b8e9c12-8856-4fe3-d821-04fbcbbd9b75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightrag[ollama] in /usr/local/lib/python3.10/dist-packages (0.1.0b6)\n",
            "Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (2.2.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (3.1.4)\n",
            "Requirement already satisfied: jsonlines<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.0.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.26.4)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.0.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (6.0.2)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.66.5)\n",
            "Requirement already satisfied: ollama<0.3.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (0.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->lightrag[ollama]) (2.1.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<5.0.0,>=4.0.0->lightrag[ollama]) (24.2.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.27.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Import Libraries***"
      ],
      "metadata": {
        "id": "FGiCmxtWUrM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "import os\n",
        "import ffmpeg\n",
        "import webrtcvad\n",
        "import wave\n",
        "from faster_whisper import WhisperModel\n",
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "from lightrag.components.model_client import OllamaClient, GroqAPIClient\n",
        "import time\n",
        "import asyncio\n",
        "import random\n",
        "import edge_tts\n",
        "from edge_tts import VoicesManager"
      ],
      "metadata": {
        "id": "ZQiRBJMaynYi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Main Pipeline Or Module for End-to-End AI Voice Assistance Pipeline***"
      ],
      "metadata": {
        "id": "6OiV5-6vUyDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=5):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  audio_path = 'audio.wav'\n",
        "  with open(audio_path,'wb') as f:\n",
        "    f.write(b)\n",
        "  return audio_path\n",
        "\n",
        "def preprocess_audio(input_file, output_file):\n",
        "    stream = ffmpeg.input(input_file)\n",
        "    stream = ffmpeg.output(stream, output_file, ar=16000, ac=1)\n",
        "    ffmpeg.run(stream)\n",
        "    vad_filter('processed_audio.wav', 'vad_filtered_audio.wav')\n",
        "\n",
        "def vad_filter(input_file, output_file, vad_threshold=0.5):\n",
        "    vad = webrtcvad.Vad()\n",
        "    vad.set_mode(2)  # 0: Aggressive VAD, 3: Very Aggressive\n",
        "\n",
        "    with wave.open(input_file, 'rb') as wf:\n",
        "        with wave.open(output_file, 'wb') as out:\n",
        "            out.setnchannels(wf.getnchannels())\n",
        "            out.setsampwidth(wf.getsampwidth())\n",
        "            out.setframerate(wf.getframerate())\n",
        "\n",
        "            frame_size = 160  # 10 ms at 16kHz\n",
        "            frame = wf.readframes(frame_size)\n",
        "            while frame:\n",
        "                if vad.is_speech(frame, wf.getframerate()):\n",
        "                    out.writeframes(frame)\n",
        "                frame = wf.readframes(frame_size)\n",
        "    transcript('vad_filtered_audio.wav')\n",
        "\n",
        "def transcript(audio_file):\n",
        "    model_size = \"medium\"\n",
        "    model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
        "    segments, info = model.transcribe(audio_file, beam_size=5)\n",
        "    prompt= \"\"\n",
        "    for segment in segments:\n",
        "        prompt += segment.text + \" \"\n",
        "\n",
        "    # Optional: Trim any extra space at the end of the prompt\n",
        "    prompt = prompt.strip()\n",
        "    print(prompt)\n",
        "    return prompt\n",
        "\n",
        "def llama(prompt):\n",
        "    qa_template = r\"\"\"<SYS>\n",
        "    You are a helpful assistant.\n",
        "    </SYS>\n",
        "    User: {{input_str}}\n",
        "    You:\"\"\"\n",
        "\n",
        "    class SimpleQA(Component):\n",
        "        def __init__(self, model_client: ModelClient, model_kwargs: dict):\n",
        "            super().__init__()\n",
        "            self.generator = Generator(\n",
        "                model_client=model_client,\n",
        "                model_kwargs=model_kwargs,\n",
        "                template=qa_template,\n",
        "            )\n",
        "\n",
        "        def call(self, input: dict) -> str:\n",
        "            return self.generator.call({\"input_str\": str(input)})\n",
        "\n",
        "        async def acall(self, input: dict) -> str:\n",
        "            return await self.generator.acall({\"input_str\": str(input)})\n",
        "\n",
        "    model = {\n",
        "        \"model_client\": OllamaClient(),\n",
        "        \"model_kwargs\": {\"model\": \"llama3.1:8b\"}\n",
        "    }\n",
        "    qa = SimpleQA(**model)\n",
        "    output=qa(f\"{prompt} Respond strictly in two sentences only.\")\n",
        "    response = output.data\n",
        "    display(f\"**Answer:** {response}\")\n",
        "    return response\n",
        "\n",
        "async def tts(text):\n",
        "    # Generate male and female TTS responses from input text and save them as audio files.\n",
        "    voices = await VoicesManager.create()  # Await the asynchronous creation of VoicesManager\n",
        "\n",
        "    # Find male and female voices\n",
        "    male_voice = voices.find(Gender=\"Male\", Language=\"en\")\n",
        "    female_voice = voices.find(Gender=\"Female\", Language=\"en\")\n",
        "\n",
        "    # Generate male voice response\n",
        "    communicate_male = edge_tts.Communicate(text, random.choice(male_voice)[\"Name\"], rate=\"-10%\", pitch=\"-10Hz\")\n",
        "    await communicate_male.save(\"male_response.mp3\")\n",
        "\n",
        "    # Generate female voice response\n",
        "    communicate_female = edge_tts.Communicate(text, random.choice(female_voice)[\"Name\"], rate=\"-10%\", pitch=\"-10Hz\")\n",
        "    await communicate_female.save(\"female_response.mp3\")\n",
        "\n",
        "def main():\n",
        "    # Prompt the user to choose recording or file path input\n",
        "    choice = input(\"Do you want to record from the microphone or enter an audio file path? (Enter 'record' or 'audio_path'): \").strip().lower()\n",
        "\n",
        "    if choice == 'record':\n",
        "        print(\"Recording from microphone...\")\n",
        "        audio_path = record()  # Record for 5 seconds (default)\n",
        "        print(f\"Audio recorded and saved to {audio_path}\")\n",
        "    elif choice == 'audio_path':\n",
        "        audio_path = input(\"Please enter the path to the audio file: \").strip()\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(\"The file does not exist. Please check the path and try again.\")\n",
        "            return\n",
        "        print(f\"Using the provided audio file: {audio_path}\")\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter 'record' or 'path'.\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the audio file\n",
        "    prompt = preprocess_audio(audio_path, 'processed_audio.wav')\n",
        "    response = llama(prompt)\n",
        "    print(response)\n",
        "\n",
        "    for i in ['processed_audio.wav', 'vad_filtered_audio.wav']:\n",
        "        os.remove(i)\n",
        "    return response\n",
        "\n",
        "# Run the main function\n",
        "response = main()\n",
        "\n",
        "#Text To Speech Conversion\n",
        "await tts(response)"
      ],
      "metadata": {
        "id": "jxViGSgLgrC-",
        "outputId": "3300148b-d557-4c3a-cf38-176f8f9f7809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you want to record from the microphone or enter an audio file path? (Enter 'record' or 'audio_path'): record\n",
            "Recording from microphone...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio recorded and saved to audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That is your purpose.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"**Answer:** I'm here to help with any questions or tasks you may have. What's on your mind?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm here to help with any questions or tasks you may have. What's on your mind?\n"
          ]
        }
      ]
    }
  ]
}